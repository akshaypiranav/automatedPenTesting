from celery import shared_task
import concurrent.futures
import json

from django.http import JsonResponse
from .utils import perform_nmap_scan, run_zap_scan, generate_pdf_from_json, add_http_protocol
from APP import models

#Using Redis and Celery Handling Queue for N number of Requests
@shared_task
def main(target_ip_value, target_url_value, urlDataId):  
    print("IN TASKS")
    global urlData
    urlData = models.Urls_of_users.objects.get(pk=urlDataId)  
    print(urlData)
    print(urlDataId)
    target_ip = target_ip_value
    zap_url = 'http://localhost:8080'
    api_key = 'lu58e3pa4ddiihfp7e6bfrtauv'
    target_url = target_url_value
    target_url = add_http_protocol(target_url)
    print(target_url)
    #Changing the url Status to In Progress
    urlData.url_status = "In Progress"
    urlData.save()
    
    #using Threadingf For Concurrency
    with concurrent.futures.ThreadPoolExecutor() as executor:
        nmap_future = executor.submit(perform_nmap_scan, target_ip, urlData)
        zap_future = executor.submit(run_zap_scan, zap_url, api_key, target_url, urlData)
        
        # Wait for both futures to complete
        nmap_result = nmap_future.result()
        zap_result = zap_future.result()

        # Parse JSON results
        json_result_nmap = json.loads(nmap_result)
        json_result_zap = json.loads(zap_result)
        
        if json_result_nmap is not None and json_result_zap is not None:
            generate_pdf_from_json(json_result_nmap, json_result_zap, urlData)
        else:
            urlData.url_status="Test Error"
            urlData.save()
            


